{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4cf663c",
   "metadata": {},
   "source": [
    "# 03 - Classification (10-fold CV + F1)\n",
    "\n",
    "This notebook runs a 10-fold stratified cross-validation with GridSearch for three classifiers (KNN, RandomForest, SVM) and compares macro F1.\n",
    "\n",
    "Inputs: `etl/datasets/movie_features.csv`\n",
    "\n",
    "Outputs: `etl/reports/model_comparison.csv`\n",
    "\n",
    "Run the cells sequentially. The implementation mirrors `notebooks/03_classification.py` but is split into runnable notebook cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e24e84d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports OK\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import json\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print('Imports OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4e2f72c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper functions defined\n"
     ]
    }
   ],
   "source": [
    "# Helper functions: load + prepare\n",
    "\n",
    "def load_data(path: Path):\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"Dataset not found: {path}\\nRun `python scripts/fetch_data.py` and `python run_etl.py` (or the individual transforms) to create it.\")\n",
    "    df = pd.read_csv(path)\n",
    "    return df\n",
    "\n",
    "\n",
    "def prepare_features(df: pd.DataFrame):\n",
    "    # Features observed in movie_features.csv: avg_rating, rating_count, rating_std, year, tmdbId\n",
    "    features = [\"avg_rating\", \"rating_count\", \"rating_std\", \"year\", \"tmdbId\"]\n",
    "    missing = [c for c in features if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing expected feature columns: {missing}\")\n",
    "\n",
    "    # Label\n",
    "    if \"label_genre\" not in df.columns:\n",
    "        raise ValueError(\"Missing label column 'label_genre' in dataset\")\n",
    "\n",
    "    X = df[features].copy()\n",
    "    y = df[\"label_genre\"].copy()\n",
    "\n",
    "    # Drop rows with missing label\n",
    "    mask = y.notna()\n",
    "    X = X[mask]\n",
    "    y = y[mask]\n",
    "\n",
    "    # For simplicity drop rows with any missing numeric feature\n",
    "    X = X.dropna()\n",
    "    y = y.loc[X.index]\n",
    "\n",
    "    # Convert types\n",
    "    X[\"rating_count\"] = X[\"rating_count\"].astype(float)\n",
    "    X[\"year\"] = X[\"year\"].astype(float)\n",
    "    X[\"tmdbId\"] = pd.to_numeric(X[\"tmdbId\"], errors=\"coerce\")\n",
    "    X = X.fillna(0)\n",
    "\n",
    "    # Encode labels\n",
    "    le = LabelEncoder()\n",
    "    y_enc = le.fit_transform(y)\n",
    "\n",
    "    return X.values, y_enc, le, X.columns.tolist()\n",
    "\n",
    "print('Helper functions defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec4536de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model selection function defined\n"
     ]
    }
   ],
   "source": [
    "# Model selection function\n",
    "\n",
    "def run_model_selection(X, y, feature_names, out_report: Path):\n",
    "    cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    scorer = make_scorer(f1_score, average=\"macro\")\n",
    "\n",
    "    candidates = [\n",
    "        (\n",
    "            \"KNN\",\n",
    "            KNeighborsClassifier(),\n",
    "            {\"n_neighbors\": [3, 5, 7], \"weights\": [\"uniform\", \"distance\"]},\n",
    "        ),\n",
    "        (\n",
    "            \"RandomForest\",\n",
    "            RandomForestClassifier(random_state=42),\n",
    "            {\"n_estimators\": [100, 200], \"max_depth\": [None, 10, 20]},\n",
    "        ),\n",
    "        (\n",
    "            \"SVM\",\n",
    "            SVC(random_state=42),\n",
    "            {\"C\": [0.1, 1.0, 10.0], \"kernel\": [\"rbf\", \"linear\"]},\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    results = []\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    for name, model, grid in candidates:\n",
    "        print(f\"\\n>>> Tuning {name} ...\")\n",
    "        gs = GridSearchCV(\n",
    "            estimator=model,\n",
    "            param_grid=grid,\n",
    "            scoring=scorer,\n",
    "            cv=cv,\n",
    "            n_jobs=-1,\n",
    "            refit=True,\n",
    "            verbose=0,\n",
    "        )\n",
    "        gs.fit(X_scaled, y)\n",
    "\n",
    "        best = gs.best_estimator_\n",
    "        best_params = gs.best_params_\n",
    "        # Re-run cross_val_score on the best estimator to get mean/std\n",
    "        scores = cross_val_score(best, X_scaled, y, cv=cv, scoring=scorer, n_jobs=-1)\n",
    "\n",
    "        row = {\n",
    "            \"model\": name,\n",
    "            \"mean_cv_f1_macro\": float(scores.mean()),\n",
    "            \"std_cv_f1_macro\": float(scores.std()),\n",
    "            \"best_params\": json.dumps(best_params, ensure_ascii=False),\n",
    "            \"n_features\": len(feature_names),\n",
    "            \"features\": \",\".join(feature_names),\n",
    "        }\n",
    "        results.append(row)\n",
    "\n",
    "        print(f\"{name} best params: {best_params}\")\n",
    "        print(f\"{name} CV f1_macro: {scores.mean():.4f} ± {scores.std():.4f}\")\n",
    "\n",
    "    df_res = pd.DataFrame(results).sort_values(\"mean_cv_f1_macro\", ascending=False)\n",
    "    out_report.parent.mkdir(parents=True, exist_ok=True)\n",
    "    df_res.to_csv(out_report, index=False, encoding=\"utf-8\")\n",
    "    print(f\"\\nSaved model comparison report -> {out_report}\")\n",
    "    return df_res\n",
    "\n",
    "print('Model selection function defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adb164c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset: C:\\Users\\Admin\\Desktop\\PJ_KTDL\\MovieRecProject_N5\\etl\\datasets\\movie_features.csv\n",
      "Dataset shape: (9675, 8)\n",
      "Prepared X shape: (9668, 5), y shape: (9668,), n_classes: 18\n",
      "\n",
      ">>> Tuning KNN ...\n",
      "KNN best params: {'n_neighbors': 3, 'weights': 'distance'}\n",
      "KNN CV f1_macro: 0.0912 ± 0.0098\n",
      "\n",
      ">>> Tuning RandomForest ...\n",
      "RandomForest best params: {'max_depth': 20, 'n_estimators': 100}\n",
      "RandomForest CV f1_macro: 0.0968 ± 0.0062\n",
      "\n",
      ">>> Tuning SVM ...\n",
      "SVM best params: {'C': 10.0, 'kernel': 'rbf'}\n",
      "SVM CV f1_macro: 0.0741 ± 0.0051\n",
      "\n",
      "Saved model comparison report -> C:\\Users\\Admin\\Desktop\\PJ_KTDL\\MovieRecProject_N5\\notebooks\\etl\\reports\\model_comparison.csv\n",
      "\n",
      "Results DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>mean_cv_f1_macro</th>\n",
       "      <th>std_cv_f1_macro</th>\n",
       "      <th>best_params</th>\n",
       "      <th>n_features</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.096845</td>\n",
       "      <td>0.006159</td>\n",
       "      <td>{\"max_depth\": 20, \"n_estimators\": 100}</td>\n",
       "      <td>5</td>\n",
       "      <td>avg_rating,rating_count,rating_std,year,tmdbId</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.091197</td>\n",
       "      <td>0.009825</td>\n",
       "      <td>{\"n_neighbors\": 3, \"weights\": \"distance\"}</td>\n",
       "      <td>5</td>\n",
       "      <td>avg_rating,rating_count,rating_std,year,tmdbId</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.074095</td>\n",
       "      <td>0.005108</td>\n",
       "      <td>{\"C\": 10.0, \"kernel\": \"rbf\"}</td>\n",
       "      <td>5</td>\n",
       "      <td>avg_rating,rating_count,rating_std,year,tmdbId</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model  mean_cv_f1_macro  std_cv_f1_macro  \\\n",
       "1  RandomForest          0.096845         0.006159   \n",
       "0           KNN          0.091197         0.009825   \n",
       "2           SVM          0.074095         0.005108   \n",
       "\n",
       "                                 best_params  n_features  \\\n",
       "1     {\"max_depth\": 20, \"n_estimators\": 100}           5   \n",
       "0  {\"n_neighbors\": 3, \"weights\": \"distance\"}           5   \n",
       "2               {\"C\": 10.0, \"kernel\": \"rbf\"}           5   \n",
       "\n",
       "                                         features  \n",
       "1  avg_rating,rating_count,rating_std,year,tmdbId  \n",
       "0  avg_rating,rating_count,rating_std,year,tmdbId  \n",
       "2  avg_rating,rating_count,rating_std,year,tmdbId  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved report at C:\\Users\\Admin\\Desktop\\PJ_KTDL\\MovieRecProject_N5\\notebooks\\etl\\reports\\model_comparison.csv\n"
     ]
    }
   ],
   "source": [
    "# Run pipeline (execute this cell)\n",
    "from IPython.display import display\n",
    "\n",
    "# Resolve dataset path robustly (works when kernel cwd is repo root or notebooks/)\n",
    "project_root = Path.cwd().resolve()\n",
    "possible_paths = [\n",
    "    project_root / \"etl\" / \"datasets\" / \"movie_features.csv\",\n",
    "    project_root.parent / \"etl\" / \"datasets\" / \"movie_features.csv\",\n",
    "]\n",
    "\n",
    "data_path = None\n",
    "for p in possible_paths:\n",
    "    if p.exists():\n",
    "        data_path = p\n",
    "        break\n",
    "\n",
    "if data_path is None:\n",
    "    raise FileNotFoundError(\n",
    "        f\"Dataset not found in expected locations: {possible_paths}\\nPlease run `python scripts/fetch_data.py` and the ETL transforms to produce `etl/intermediate/*.parquet` and then `etl/datasets/movie_features.csv`\"\n",
    "    )\n",
    "\n",
    "out_report = project_root / \"etl\" / \"reports\" / \"model_comparison.csv\"\n",
    "\n",
    "print(\"Loading dataset:\", data_path)\n",
    "df = load_data(data_path)\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "\n",
    "X, y, le, feature_names = prepare_features(df)\n",
    "print(f\"Prepared X shape: {X.shape}, y shape: {y.shape}, n_classes: {len(le.classes_)}\")\n",
    "\n",
    "results = run_model_selection(X, y, feature_names, out_report)\n",
    "\n",
    "print('\\nResults DataFrame:')\n",
    "display(results)\n",
    "\n",
    "print('\\nSaved report at', out_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bef4e405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved corrected report at C:\\Users\\Admin\\Desktop\\PJ_KTDL\\MovieRecProject_N5\\etl\\reports\\model_comparison.csv\n"
     ]
    }
   ],
   "source": [
    "# Ensure results are also saved into repo root etl/reports (not inside notebooks/etl/...)\n",
    "if 'results' in globals():\n",
    "    repo_root = data_path.parents[2]\n",
    "    correct_out = repo_root / 'etl' / 'reports' / 'model_comparison.csv'\n",
    "    correct_out.parent.mkdir(parents=True, exist_ok=True)\n",
    "    results.to_csv(correct_out, index=False, encoding='utf-8')\n",
    "    print('Saved corrected report at', correct_out)\n",
    "else:\n",
    "    print('Variable `results` not found in notebook state; run the pipeline cell first.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
